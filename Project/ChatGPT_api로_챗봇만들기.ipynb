{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MXSA9olBfVMk"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"\" ## ì‚­ì œ ìš”ë§"
      ],
      "metadata": {
        "id": "9xQNDEWbjHm8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë‹µë³€ìƒì„± í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "Wzh8pVHmjRAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(x):\n",
        "  gpt_prompt = [{\n",
        "      \"role\": \"system\",\n",
        "      \"content\":\"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì˜ì•Œë ¤ì£¼ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì…ë‹ˆë‹¤. ì…ë ¥ì— ëŒ€í•´ í•µì‹¬ê³¼ ì¹œì ˆí•˜ê²Œ ì˜ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\"\n",
        "  }]\n",
        "\n",
        "  gpt_prompt.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": x\n",
        "  })\n",
        "\n",
        "  gpt_response = openai.ChatCompletion.create(\n",
        "      model = \"gpt-3.5-turbo\",\n",
        "      messages = gpt_prompt\n",
        "  )\n",
        "\n",
        "  return gpt_response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "I9_nzDsqjO_o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen(\"ì•ˆë…•í•˜ì„¸ìš”, ë„ˆëŠ” ëˆ„êµ¬ì•¼?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ChtY7mkvlhLy",
        "outputId": "b3cecf92-a823-4e46-d43e-b7e3cf8baa28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen(\"ChatGPTê°€ ì˜í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì´ì•¼?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_3KmE1rRl6vc",
        "outputId": "5e4685bb-ccb5-4da4-fa94-77f6171727a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ChatGPTëŠ” ìì—°ì–´ ì²˜ë¦¬ ë° ì´í•´ ê¸°ìˆ ì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ ìƒì„±í•˜ê³  ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ëŠ” ë° ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë˜í•œ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”í•  ìˆ˜ ìˆìœ¼ë©° ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ í•™ìŠµí•˜ì—¬ ì ì°¨ì ìœ¼ë¡œ ë” ìœ ì°½í•˜ê³  ì˜ë¯¸ ìˆëŠ” ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.ê·¸ë˜ì„œ ChatGPTëŠ” ì¼ìƒì ì¸ ëŒ€í™”ë¶€í„° ì •ë³´ ì œê³µ, ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€, ì¡°ì–¸ ì œê³µ ë“± ë‹¤ì–‘í•œ ìƒí™©ì— ìœ ìš©í•˜ê²Œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "pvpcEs4Hmc0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def inference(text):\n",
        "  return gen(text)\n",
        "\n",
        "demo = gr.Interface(fn=inference, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "xx7t6sWMl-90",
        "outputId": "a84586c9-884e-48d8-b116-f766d005f90d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a93fca3b5c2ed7c255.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a93fca3b5c2ed7c255.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a93fca3b5c2ed7c255.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë¬¸ë§¥ ë§¥ë½ í™•ì¥ ë° ê¸°ì–µ"
      ],
      "metadata": {
        "id": "7Rohtj2UnWk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_prompt = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì…ë‹ˆë‹¤. ì…ë ¥ê°’ì— ëŒ€í•´ í•µì‹¬ê³¼ ê°„ê²°í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\",\n",
        "}, {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"ê²¨ìš¸ì— ë¨¹ê¸° ì¢‹ì€ ê³¼ì¼ì„ ì¶”ì²œí•´ì¤˜\"\n",
        "}, {\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \"ê²¨ìš¸ì—ëŠ” ë§ê³ , í¬ë„, ê±°ë´‰, ë³µìˆ­ì•„ ë“±ì´ ë”°ëœ»í•˜ê³  ë§›ìˆê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ê³¼ì¼ì…ë‹ˆë‹¤.\",\n",
        "}, {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"ìœ„ ë¬¸ì¥ìœ¼ë¡œ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜\",\n",
        "}]\n",
        "\n",
        "gpt_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=gpt_prompt\n",
        ")\n",
        "\n",
        "gpt_response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rKkvZ0idmseM",
        "outputId": "6405d3cb-f2f8-4220-8eae-e32fe9c05a42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In winter, fruits such as mango, grapes, persimmons, and peaches are recommended for their warmth and deliciousness.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì±—ë´‡ Gradio"
      ],
      "metadata": {
        "id": "XrCMqbf9oy74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(input, history):\n",
        "  history.append({\"role\": \"user\", \"content\": input})\n",
        "\n",
        "  gpt_response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=history\n",
        "  )\n",
        "\n",
        "  response = gpt_response[\"choices\"][0][\"message\"]['content']\n",
        "  history.append({\"role\":\"assistant\", \"content\":response})\n",
        "  messages = [(history[i][\"content\"], history[i+1][\"content\"]) for i in range(1, len(history), 2)]\n",
        "\n",
        "  return messages, history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(label=\"ChatBot\")\n",
        "\n",
        "    state = gr.State([{\n",
        "        \"role\":\"system\",\n",
        "        \"content\":\"ë‹¹ì‹ ì€ ì•„ì£¼ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì…ë‹ˆë‹¤. ì…ë ¥ê°’ì— ëŒ€í•´ í•µì‹¬ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\"\n",
        "    }])\n",
        "\n",
        "    with gr.Row():\n",
        "        # [ìˆ˜ì •ëœ ë¶€ë¶„] .style()ì„ ì œê±°í•˜ê³  container=Falseë¥¼ ì¸ìë¡œ ë„£ì—ˆìŠµë‹ˆë‹¤.\n",
        "        # scale=7ì„ ì¶”ê°€í•˜ì—¬ ì…ë ¥ì°½ì´ ë²„íŠ¼ë³´ë‹¤ ë„“ê²Œ ë³´ì´ë„ë¡ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.\n",
        "        txt = gr.Textbox(\n",
        "            show_label=False,\n",
        "            placeholder=\"ì±—ë´‡ì—ê²Œ ì•„ë¬´ê±°ë‚˜ ë¬¼ì–´ë³´ì„¸ìš”\",\n",
        "            container=False,\n",
        "            scale=7\n",
        "        )\n",
        "\n",
        "    # ì…ë ¥ í›„ ì—”í„°ë¥¼ ì³¤ì„ ë•Œ ì‹¤í–‰\n",
        "    txt.submit(predict, [txt, state], [chatbot, state])\n",
        "\n",
        "    # (ì„ íƒì‚¬í•­) ì „ì†¡ í›„ ì…ë ¥ì°½ì„ ë¹„ìš°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”\n",
        "    # txt.submit(lambda: \"\", None, txt)\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "hK0l9lGvoOZS",
        "outputId": "b0baf693-7c31-46a1-a888-b3f0f2ad0132"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2769502868.py:18: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"ChatBot\")\n",
            "/tmp/ipython-input-2769502868.py:18: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"ChatBot\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4a7fb5003c45a3473e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4a7fb5003c45a3473e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://4a7fb5003c45a3473e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ì•ˆã„´"
      ],
      "metadata": {
        "id": "wBTYpxEqruS5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}